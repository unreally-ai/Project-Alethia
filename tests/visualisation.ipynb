{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "\n",
    "# setup\n",
    "DATAPATH = 'smallchungus.csv' \n",
    "# device\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>head</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27636</th>\n",
       "      <td>23420</td>\n",
       "      <td>ISIS Militants Allegedly Contracted Ebola</td>\n",
       "      <td>1351</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>There may be yet another bug in iOS 8, Apple's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13167</th>\n",
       "      <td>11979</td>\n",
       "      <td>Confusion swirls, details murky in arrest of I...</td>\n",
       "      <td>720</td>\n",
       "      <td>discuss</td>\n",
       "      <td>DNA tests have confirmed that a daughter and a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>29334</td>\n",
       "      <td>Dog found abandoned at Scottish train station ...</td>\n",
       "      <td>1642</td>\n",
       "      <td>agree</td>\n",
       "      <td>The Scottish SPCA is appealing to the public f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30499</th>\n",
       "      <td>26318</td>\n",
       "      <td>Was Alleged Audio of Michael Brown Shooting on...</td>\n",
       "      <td>1481</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>The bullet ricochets off the man's helmet, pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29693</th>\n",
       "      <td>25669</td>\n",
       "      <td>Isis 'fed murdered kidnap victim to his own mo...</td>\n",
       "      <td>1442</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>Updates at 5:10 p.m.\\n\\nSoldier killed in War ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               head  Body ID  \\\n",
       "27636       23420          ISIS Militants Allegedly Contracted Ebola     1351   \n",
       "13167       11979  Confusion swirls, details murky in arrest of I...      720   \n",
       "490         29334  Dog found abandoned at Scottish train station ...     1642   \n",
       "30499       26318  Was Alleged Audio of Michael Brown Shooting on...     1481   \n",
       "29693       25669  Isis 'fed murdered kidnap victim to his own mo...     1442   \n",
       "\n",
       "          Stance                                               body  \n",
       "27636  unrelated  There may be yet another bug in iOS 8, Apple's...  \n",
       "13167    discuss  DNA tests have confirmed that a daughter and a...  \n",
       "490        agree  The Scottish SPCA is appealing to the public f...  \n",
       "30499  unrelated  The bullet ricochets off the man's helmet, pro...  \n",
       "29693  unrelated  Updates at 5:10 p.m.\\n\\nSoldier killed in War ...  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATAPATH)\n",
    "df = shuffle(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in string & returns a cleaned string of all non-stop-words\n",
    "def preprocess(text, lemmatizer = WordNetLemmatizer()):\n",
    "    sw = set(stopwords.words('english'))\n",
    "    text = re.sub(r'[^\\w\\s]', '', text).lower()\n",
    "    s = \"\"\n",
    "    for word in text.split():\n",
    "        if word not in sw:\n",
    "                s += (lemmatizer.lemmatize(word) + \" \")\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "max_words = 20\n",
    "embed_len=300\n",
    "global_vectors = GloVe(name='840B', dim=embed_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes string, returns 6000 dim GloVe vector\n",
    "def to_vector(s):\n",
    "    X = tokenizer(preprocess(s))\n",
    "    # fill / cut tokens to max size\n",
    "    if len(X) < max_words:\n",
    "        X = X+[\"\"]*(max_words-len(X))\n",
    "    else:\n",
    "        X = X[:max_words]\n",
    "\n",
    "    X_tensor = torch.zeros(1, max_words, embed_len)\n",
    "    for i, j in enumerate(X):\n",
    "        X_tensor[0][i] = global_vectors.get_vecs_by_tokens(j)\n",
    "    return(X_tensor.reshape(1, -1))\n",
    "\n",
    "def combined_vector(x, y):\n",
    "    x = to_vector(x)\n",
    "    y = to_vector(y)\n",
    "    return torch.cat((x, y), 1).numpy()\n",
    "\n",
    "def cosim(x, y):\n",
    "    x = to_vector(x)\n",
    "    y = to_vector(y)\n",
    "    cosim = cosine_similarity(x, y)\n",
    "    return cosim[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stance_to_colour(r):\n",
    "    s = r[\"Stance\"]\n",
    "    stance_map = {\n",
    "                \"agree\": \"lime\",\n",
    "                \"disagree\": \"red\",\n",
    "                \"discuss\": \"blue\",\n",
    "                \"unrelated\": \"grey\"\n",
    "            }\n",
    "    y_data = stance_map[s]\n",
    "    return y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "#targets = [combined_vector(df[\"head\"][i], df[\"body\"][i])[0] for i in range(3000)]\n",
    "targets = [to_vector(df[\"body\"][i])[0].numpy() for i in range(3000)]\n",
    "#cs = [cosim(df[\"head\"][i], df[\"body\"][i])[0] for i in range(3000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_labels = []\n",
    "for i in range(3000):\n",
    "    colour_labels.append(stance_to_colour(df.iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0.27138162 0.10205631 0.11079711 ... 0.14447063 0.20737205 0.16762617].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/cas/Downloads/Unreally/notebooks/visualisation.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cas/Downloads/Unreally/notebooks/visualisation.ipynb#X16sdW50aXRsZWQ%3D?line=26'>27</a>\u001b[0m train_counts, count_vectorizer \u001b[39m=\u001b[39m cv(df[\u001b[39m\"\u001b[39m\u001b[39mhead\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cas/Downloads/Unreally/notebooks/visualisation.ipynb#X16sdW50aXRsZWQ%3D?line=27'>28</a>\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m16\u001b[39m, \u001b[39m16\u001b[39m))          \n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/cas/Downloads/Unreally/notebooks/visualisation.ipynb#X16sdW50aXRsZWQ%3D?line=28'>29</a>\u001b[0m plot_LSA(targets, colour_labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cas/Downloads/Unreally/notebooks/visualisation.ipynb#X16sdW50aXRsZWQ%3D?line=29'>30</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "\u001b[1;32m/home/cas/Downloads/Unreally/notebooks/visualisation.ipynb Cell 10\u001b[0m in \u001b[0;36mplot_LSA\u001b[0;34m(test_data, test_labels, savepath, plot)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cas/Downloads/Unreally/notebooks/visualisation.ipynb#X16sdW50aXRsZWQ%3D?line=11'>12</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_LSA\u001b[39m(test_data, test_labels, savepath\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPCA_demo.csv\u001b[39m\u001b[39m\"\u001b[39m, plot\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cas/Downloads/Unreally/notebooks/visualisation.ipynb#X16sdW50aXRsZWQ%3D?line=12'>13</a>\u001b[0m         lsa \u001b[39m=\u001b[39m TruncatedSVD(n_components\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/cas/Downloads/Unreally/notebooks/visualisation.ipynb#X16sdW50aXRsZWQ%3D?line=13'>14</a>\u001b[0m         lsa\u001b[39m.\u001b[39;49mfit(test_data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cas/Downloads/Unreally/notebooks/visualisation.ipynb#X16sdW50aXRsZWQ%3D?line=14'>15</a>\u001b[0m         lsa_scores \u001b[39m=\u001b[39m lsa\u001b[39m.\u001b[39mtransform(test_data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cas/Downloads/Unreally/notebooks/visualisation.ipynb#X16sdW50aXRsZWQ%3D?line=15'>16</a>\u001b[0m         color_mapper \u001b[39m=\u001b[39m {label:idx \u001b[39mfor\u001b[39;00m idx,label \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mset\u001b[39m(test_labels))}\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:192\u001b[0m, in \u001b[0;36mTruncatedSVD.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    177\u001b[0m     \u001b[39m\"\"\"Fit model on training data X.\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39m        Returns the transformer object.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_transform(X)\n\u001b[1;32m    193\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:218\u001b[0m, in \u001b[0;36mTruncatedSVD.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39m\"\"\"Fit model to X and perform dimensionality reduction on X.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39m    Reduced version of X. This will always be a dense array.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    211\u001b[0m check_scalar(\n\u001b[1;32m    212\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_oversamples,\n\u001b[1;32m    213\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mn_oversamples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    214\u001b[0m     min_val\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    215\u001b[0m     target_type\u001b[39m=\u001b[39mIntegral,\n\u001b[1;32m    216\u001b[0m )\n\u001b[0;32m--> 218\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m], ensure_min_features\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m    219\u001b[0m random_state \u001b[39m=\u001b[39m check_random_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n\u001b[1;32m    221\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgorithm \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marpack\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    878\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 879\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    880\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    881\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    884\u001b[0m         )\n\u001b[1;32m    886\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    887\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    888\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    889\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    890\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.27138162 0.10205631 0.11079711 ... 0.14447063 0.20737205 0.16762617].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1152x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def cv(data):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    emb = count_vectorizer.fit_transform(data)\n",
    "    return emb, count_vectorizer\n",
    "\n",
    "def plot_LSA(test_data, test_labels, savepath=\"PCA_demo.csv\", plot=True):\n",
    "        lsa = TruncatedSVD(n_components=2)\n",
    "        lsa.fit(test_data)\n",
    "        lsa_scores = lsa.transform(test_data)\n",
    "        color_mapper = {label:idx for idx,label in enumerate(set(test_labels))}\n",
    "        color_column = [color_mapper[label] for label in test_labels]\n",
    "        colors = [\"lime\", \"red\", \"blue\", \"grey\"]\n",
    "        if plot:\n",
    "            plt.scatter(lsa_scores[:,0], lsa_scores[:,1], s=8, alpha=.8, c=test_labels, cmap=matplotlib.colors.ListedColormap(colors))\n",
    "            green_patch = mpatches.Patch(color='lime', label='agree')\n",
    "            red_patch = mpatches.Patch(color=\"red\", label='disagree')\n",
    "            blue_patch = mpatches.Patch(color=\"blue\", label='discuss')\n",
    "            grey_patch = mpatches.Patch(color=\"grey\", label='unrelated')\n",
    "            plt.legend(handles=[green_patch, red_patch, blue_patch, grey_patch], prop={'size': 30})\n",
    "\n",
    "train_counts, count_vectorizer = cv(df[\"head\"])\n",
    "fig = plt.figure(figsize=(16, 16))          \n",
    "plot_LSA(targets, colour_labels)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
